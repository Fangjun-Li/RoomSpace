<div align="center">
  <h1>ğŸ§ RoomSpace Benchmark</h1>
  <p>
    ğŸŒ <a href="https://roomspace-benchmark.web.app/">Homepage</a> â€¢ 
    ğŸ¤— <a href="https://huggingface.co/datasets/Fangjun/RoomSpace">Hugging Face</a> â€¢ 
    <img src="img/DOI_logo.svg" > <a href="https://archive.researchdata.leeds.ac.uk/1293/">Dataset</a> â€¢ 
    ğŸ“™ <a href="https://arxiv.org/abs/2405.15064">Paper</a>
  </p>
   <p><em>Simplify LLM evaluation using a convenient Colab notebook.</em></p>
   <a href="https://colab.research.google.com/drive/1fAK8J1UHAjMm-mNVsuzIbEZd-SZG6bX-?usp=sharing"><img src="img/colab.svg" alt="Open In Colab"></a></center>
</div>
<br/>


## ğŸ” Overview

This repo contains the evaluation code for the  IJCAI-24 paper "[Reframing Spatial Reasoning Evaluation in Language Models: A Real-World Simulation Benchmark for Qualitative Reasoning](https://arxiv.org/pdf/2405.15064.pdf)"
